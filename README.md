# CSE527A_llm_attack

A mini project for CSE527A Natural Language Processing

This repository replicates LLM attacks using Mandarin Chinese using the method and dataset introduced in "[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)" by Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico Kolter, and Matt Fredrikson.

Usage:

Download repo of https://github.com/llm-attacks/llm-attacks

Put main_chinese.ipynb, get_results.ipynb, harmful_behaviors.xlsx into the main folder of llm-attacks

Run training using main_chinese.ipynb

Run evaluation using get_results.ipynb after training
